{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "EAcyfnVsQCX5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\.conda\\envs\\Tensorflow\\lib\\site-packages\\numpy\\_distributor_init.py:32: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\user\\.conda\\envs\\Tensorflow\\lib\\site-packages\\numpy\\.libs\\libopenblas.PYQHXLVVQ7VESDPUVUADXEVJOBGHJPAY.gfortran-win_amd64.dll\n",
      "C:\\Users\\user\\.conda\\envs\\Tensorflow\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.callbacks import *\n",
    "import tensorflow_probability as tfp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 320
    },
    "id": "aZDfkKJPTfyA",
    "outputId": "ac979d85-0096-43cb-ca95-d4bae1dcb044"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_probability\n",
      "  Downloading tensorflow_probability-0.17.0-py2.py3-none-any.whl (6.5 MB)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\user\\.conda\\envs\\tensorflow\\lib\\site-packages (from tensorflow_probability) (1.21.6)\n",
      "Requirement already satisfied: cloudpickle>=1.3 in c:\\users\\user\\.conda\\envs\\tensorflow\\lib\\site-packages (from tensorflow_probability) (1.6.0)\n",
      "Requirement already satisfied: gast>=0.3.2 in c:\\users\\user\\.conda\\envs\\tensorflow\\lib\\site-packages (from tensorflow_probability) (0.3.3)\n",
      "Collecting dm-tree\n",
      "  Downloading dm_tree-0.1.7-cp37-cp37m-win_amd64.whl (91 kB)\n",
      "Requirement already satisfied: decorator in c:\\users\\user\\.conda\\envs\\tensorflow\\lib\\site-packages (from tensorflow_probability) (4.4.2)\n",
      "Requirement already satisfied: absl-py in c:\\users\\user\\.conda\\envs\\tensorflow\\lib\\site-packages (from tensorflow_probability) (1.2.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\user\\.conda\\envs\\tensorflow\\lib\\site-packages (from tensorflow_probability) (1.15.0)\n",
      "Installing collected packages: dm-tree, tensorflow-probability\n",
      "Successfully installed dm-tree-0.1.7 tensorflow-probability-0.17.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oDwMzo5bQEre",
    "outputId": "edd02e19-2893-4168-e9ad-1e69f940fdff"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SOYjN1oWpdHX"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('eurusd_h1_5000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1GnhIePQShe",
    "outputId": "ae617b02-ef7c-4422-b42b-c83812df1825"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2021-11-08 02:00:00\n",
       "1       2021-11-08 03:00:00\n",
       "2       2021-11-08 04:00:00\n",
       "3       2021-11-08 05:00:00\n",
       "4       2021-11-08 06:00:00\n",
       "               ...         \n",
       "4995    2022-08-25 10:00:00\n",
       "4996    2022-08-25 11:00:00\n",
       "4997    2022-08-25 12:00:00\n",
       "4998    2022-08-25 13:00:00\n",
       "4999    2022-08-25 14:00:00\n",
       "Name: time, Length: 5000, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pop(\"Unnamed: 0\")\n",
    "df.pop(\"time\")\n",
    "#df.pop(\"open\")\n",
    "#df.pop(\"high\")\n",
    "#df.pop(\"low\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "tynp9S92QUCj",
    "outputId": "b1b5bf50-2ed7-4b49-b5ea-544d6b884969"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.15680</td>\n",
       "      <td>1.15680</td>\n",
       "      <td>1.15582</td>\n",
       "      <td>1.15604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.15604</td>\n",
       "      <td>1.15624</td>\n",
       "      <td>1.15539</td>\n",
       "      <td>1.15548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.15548</td>\n",
       "      <td>1.15593</td>\n",
       "      <td>1.15532</td>\n",
       "      <td>1.15593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.15593</td>\n",
       "      <td>1.15623</td>\n",
       "      <td>1.15574</td>\n",
       "      <td>1.15577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.15578</td>\n",
       "      <td>1.15634</td>\n",
       "      <td>1.15566</td>\n",
       "      <td>1.15610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1.00106</td>\n",
       "      <td>1.00237</td>\n",
       "      <td>0.99953</td>\n",
       "      <td>0.99996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.99994</td>\n",
       "      <td>1.00122</td>\n",
       "      <td>0.99871</td>\n",
       "      <td>1.00072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1.00074</td>\n",
       "      <td>1.00113</td>\n",
       "      <td>0.99868</td>\n",
       "      <td>0.99972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.99972</td>\n",
       "      <td>0.99979</td>\n",
       "      <td>0.99741</td>\n",
       "      <td>0.99803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.99806</td>\n",
       "      <td>0.99949</td>\n",
       "      <td>0.99762</td>\n",
       "      <td>0.99860</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         open     high      low    close\n",
       "0     1.15680  1.15680  1.15582  1.15604\n",
       "1     1.15604  1.15624  1.15539  1.15548\n",
       "2     1.15548  1.15593  1.15532  1.15593\n",
       "3     1.15593  1.15623  1.15574  1.15577\n",
       "4     1.15578  1.15634  1.15566  1.15610\n",
       "...       ...      ...      ...      ...\n",
       "4995  1.00106  1.00237  0.99953  0.99996\n",
       "4996  0.99994  1.00122  0.99871  1.00072\n",
       "4997  1.00074  1.00113  0.99868  0.99972\n",
       "4998  0.99972  0.99979  0.99741  0.99803\n",
       "4999  0.99806  0.99949  0.99762  0.99860\n",
       "\n",
       "[5000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "jFsBdaIyQ2i3"
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(df.values)\n",
    "transformed_dataset = scaler.transform(df.values)\n",
    "transformed_df = pd.DataFrame(data = transformed_dataset, index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-ZQccWkRQ5wH"
   },
   "outputs": [],
   "source": [
    "number_of_rows = df.values.shape[0]\n",
    "window_length= 10 # the number of past games needed to make prediction\n",
    "number_of_features = df.values.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "y-qtaQRGQ9eQ"
   },
   "outputs": [],
   "source": [
    "train = np.empty([number_of_rows-window_length, window_length, number_of_features], dtype =float)\n",
    "label = np.empty([number_of_rows-window_length, number_of_features], dtype = float)\n",
    "window_length = 10\n",
    "\n",
    "for i in range(0, number_of_rows-window_length):\n",
    "    train[i] = transformed_df.iloc[i:i+window_length, 0: number_of_features]\n",
    "    label[i] = transformed_df.iloc[i+window_length: i+window_length+1, 0: number_of_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "id": "gXyveAA_RBW9"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  \n",
    "#layers.experimental.preprocessing.Rescaling(1./255),\n",
    "layers.LSTM(4),\n",
    "layers.Dense(64, input_dim=8, activation=None),\n",
    "layers.Dense(14, activation=None),\n",
    "layers.Dense(4, activation=None),\n",
    "])\n",
    "\n",
    "#model.compile(optimizer=tf.keras.optimizers.Nadam(learning_rate=0.1), loss='mae', metrics=['accuracy'])\n",
    "model.compile(optimizer=tf.keras.optimizers.Nadam(), loss='mae', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-nZY4Xh8REzL",
    "outputId": "89e99a4e-a940-436e-dc7e-bea4dd4af721"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0555 - accuracy: 0.2870\n",
      "Epoch 1: val_accuracy improved from -inf to 0.07816, saving model to my_model_weights2.h5\n",
      "1497/1497 [==============================] - 79s 15ms/step - loss: 0.0555 - accuracy: 0.2872 - val_loss: 0.0636 - val_accuracy: 0.0782\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.3042\n",
      "Epoch 1: val_accuracy improved from 0.07816 to 0.24248, saving model to my_model_weights2.h5\n",
      "1497/1497 [==============================] - 19s 13ms/step - loss: 0.0270 - accuracy: 0.3042 - val_loss: 0.0294 - val_accuracy: 0.2425\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.3055\n",
      "Epoch 1: val_accuracy improved from 0.24248 to 0.48096, saving model to my_model_weights2.h5\n",
      "1497/1497 [==============================] - 20s 13ms/step - loss: 0.0246 - accuracy: 0.3055 - val_loss: 0.0252 - val_accuracy: 0.4810\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.3237\n",
      "Epoch 1: val_accuracy did not improve from 0.48096\n",
      "1497/1497 [==============================] - 20s 13ms/step - loss: 0.0225 - accuracy: 0.3235 - val_loss: 0.0299 - val_accuracy: 0.0782\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0225 - accuracy: 0.3061\n",
      "Epoch 1: val_accuracy did not improve from 0.48096\n",
      "1497/1497 [==============================] - 20s 13ms/step - loss: 0.0224 - accuracy: 0.3068 - val_loss: 0.0250 - val_accuracy: 0.2004\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0224 - accuracy: 0.3099\n",
      "Epoch 1: val_accuracy improved from 0.48096 to 0.49699, saving model to my_model_weights2.h5\n",
      "1497/1497 [==============================] - 20s 14ms/step - loss: 0.0224 - accuracy: 0.3100 - val_loss: 0.0400 - val_accuracy: 0.4970\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0197 - accuracy: 0.3228\n",
      "Epoch 1: val_accuracy did not improve from 0.49699\n",
      "1497/1497 [==============================] - 20s 13ms/step - loss: 0.0197 - accuracy: 0.3222 - val_loss: 0.0210 - val_accuracy: 0.2004\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0198 - accuracy: 0.3193\n",
      "Epoch 1: val_accuracy improved from 0.49699 to 0.49900, saving model to my_model_weights2.h5\n",
      "1497/1497 [==============================] - 21s 14ms/step - loss: 0.0199 - accuracy: 0.3193 - val_loss: 0.0207 - val_accuracy: 0.4990\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0169 - accuracy: 0.3351\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 21s 14ms/step - loss: 0.0169 - accuracy: 0.3351 - val_loss: 0.0282 - val_accuracy: 0.3768\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.3224\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 21s 14ms/step - loss: 0.0174 - accuracy: 0.3222 - val_loss: 0.0256 - val_accuracy: 0.4870\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.3213\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 21s 14ms/step - loss: 0.0173 - accuracy: 0.3213 - val_loss: 0.0183 - val_accuracy: 0.3908\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3208\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 22s 14ms/step - loss: 0.0175 - accuracy: 0.3206 - val_loss: 0.0157 - val_accuracy: 0.3808\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3224\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 21s 14ms/step - loss: 0.0176 - accuracy: 0.3222 - val_loss: 0.0243 - val_accuracy: 0.1303\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.3186\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 23s 15ms/step - loss: 0.0174 - accuracy: 0.3189 - val_loss: 0.0212 - val_accuracy: 0.2425\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3222\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 22s 14ms/step - loss: 0.0176 - accuracy: 0.3218 - val_loss: 0.0307 - val_accuracy: 0.4128\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3258\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 22s 15ms/step - loss: 0.0176 - accuracy: 0.3253 - val_loss: 0.0296 - val_accuracy: 0.4709\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3226\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 22s 14ms/step - loss: 0.0175 - accuracy: 0.3229 - val_loss: 0.0171 - val_accuracy: 0.4870\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3217\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 22s 15ms/step - loss: 0.0175 - accuracy: 0.3220 - val_loss: 0.0409 - val_accuracy: 0.4289\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.3111\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 22s 15ms/step - loss: 0.0174 - accuracy: 0.3111 - val_loss: 0.0181 - val_accuracy: 0.4910\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3220\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 22s 14ms/step - loss: 0.0177 - accuracy: 0.3224 - val_loss: 0.0248 - val_accuracy: 0.4228\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3226\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 21s 14ms/step - loss: 0.0177 - accuracy: 0.3224 - val_loss: 0.0205 - val_accuracy: 0.2625\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3289\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 22s 14ms/step - loss: 0.0174 - accuracy: 0.3291 - val_loss: 0.0197 - val_accuracy: 0.3968\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3249\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 22s 15ms/step - loss: 0.0175 - accuracy: 0.3249 - val_loss: 0.0282 - val_accuracy: 0.0782\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3144\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 22s 14ms/step - loss: 0.0177 - accuracy: 0.3144 - val_loss: 0.0254 - val_accuracy: 0.2365\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3266\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 24s 16ms/step - loss: 0.0175 - accuracy: 0.3267 - val_loss: 0.0209 - val_accuracy: 0.2004\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3152\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 23s 16ms/step - loss: 0.0176 - accuracy: 0.3155 - val_loss: 0.0174 - val_accuracy: 0.4689\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3188\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 20s 14ms/step - loss: 0.0176 - accuracy: 0.3189 - val_loss: 0.0264 - val_accuracy: 0.4790\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3168\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 19s 12ms/step - loss: 0.0175 - accuracy: 0.3166 - val_loss: 0.0219 - val_accuracy: 0.3487\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.3284\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3284 - val_loss: 0.0206 - val_accuracy: 0.4930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3173\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3173 - val_loss: 0.0211 - val_accuracy: 0.3026\n",
      "1492/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3177\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3177 - val_loss: 0.0180 - val_accuracy: 0.2004\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.3140\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3140 - val_loss: 0.0194 - val_accuracy: 0.4950\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3197\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3198 - val_loss: 0.0178 - val_accuracy: 0.4449\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3231\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3229 - val_loss: 0.0160 - val_accuracy: 0.4990\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3266\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3262 - val_loss: 0.0213 - val_accuracy: 0.4870\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3130\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0178 - accuracy: 0.3137 - val_loss: 0.0181 - val_accuracy: 0.4790\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3242\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3242 - val_loss: 0.0385 - val_accuracy: 0.4529\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.3280\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 17s 11ms/step - loss: 0.0177 - accuracy: 0.3280 - val_loss: 0.0281 - val_accuracy: 0.0782\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.3153\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3153 - val_loss: 0.0175 - val_accuracy: 0.4910\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3164\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3164 - val_loss: 0.0182 - val_accuracy: 0.4810\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3320\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3320 - val_loss: 0.0208 - val_accuracy: 0.2004\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3146\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 17s 11ms/step - loss: 0.0178 - accuracy: 0.3146 - val_loss: 0.0418 - val_accuracy: 0.4950\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3182\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0178 - accuracy: 0.3182 - val_loss: 0.0166 - val_accuracy: 0.2024\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.3126\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3126 - val_loss: 0.0182 - val_accuracy: 0.2505\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3124\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3131 - val_loss: 0.0689 - val_accuracy: 0.3848\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3133\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 17s 12ms/step - loss: 0.0175 - accuracy: 0.3135 - val_loss: 0.0226 - val_accuracy: 0.4569\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3298\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0178 - accuracy: 0.3298 - val_loss: 0.0279 - val_accuracy: 0.2826\n",
      "1492/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3186\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3184 - val_loss: 0.0192 - val_accuracy: 0.4790\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.3155\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3155 - val_loss: 0.0260 - val_accuracy: 0.0902\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3157\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 17s 11ms/step - loss: 0.0175 - accuracy: 0.3160 - val_loss: 0.0356 - val_accuracy: 0.2004\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.3273\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0173 - accuracy: 0.3273 - val_loss: 0.0205 - val_accuracy: 0.4970\n",
      "1492/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3228\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3235 - val_loss: 0.0180 - val_accuracy: 0.2505\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3093\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3088 - val_loss: 0.0212 - val_accuracy: 0.2004\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3327\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3327 - val_loss: 0.0217 - val_accuracy: 0.1864\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3246\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3246 - val_loss: 0.0163 - val_accuracy: 0.3988\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3226\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3222 - val_loss: 0.0243 - val_accuracy: 0.2004\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3235\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 17s 11ms/step - loss: 0.0176 - accuracy: 0.3235 - val_loss: 0.0196 - val_accuracy: 0.4790\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3166\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3166 - val_loss: 0.0174 - val_accuracy: 0.4790\n",
      "1492/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3233\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3233 - val_loss: 0.0177 - val_accuracy: 0.2766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3224\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3224 - val_loss: 0.0274 - val_accuracy: 0.0782\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3050\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3057 - val_loss: 0.0222 - val_accuracy: 0.2004\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.3164\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3164 - val_loss: 0.0220 - val_accuracy: 0.4770\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.3102\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3102 - val_loss: 0.0186 - val_accuracy: 0.4810\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3264\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3264 - val_loss: 0.0192 - val_accuracy: 0.4850\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.3291\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 17s 11ms/step - loss: 0.0174 - accuracy: 0.3295 - val_loss: 0.0321 - val_accuracy: 0.3066\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.3184\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0174 - accuracy: 0.3184 - val_loss: 0.0268 - val_accuracy: 0.1984\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3302\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3304 - val_loss: 0.0197 - val_accuracy: 0.4890\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3211\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3213 - val_loss: 0.0190 - val_accuracy: 0.4309\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3190\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3193 - val_loss: 0.0180 - val_accuracy: 0.3467\n",
      "1492/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3202\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3211 - val_loss: 0.0216 - val_accuracy: 0.4850\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3157\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 17s 12ms/step - loss: 0.0177 - accuracy: 0.3160 - val_loss: 0.0177 - val_accuracy: 0.2004\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3200\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3200 - val_loss: 0.0196 - val_accuracy: 0.4128\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.3231\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0174 - accuracy: 0.3233 - val_loss: 0.0196 - val_accuracy: 0.4810\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3204\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.3206 - val_loss: 0.0175 - val_accuracy: 0.4649\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3235\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3235 - val_loss: 0.0172 - val_accuracy: 0.4830\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.3126\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3126 - val_loss: 0.0172 - val_accuracy: 0.2044\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0173 - accuracy: 0.3190\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0173 - accuracy: 0.3189 - val_loss: 0.0209 - val_accuracy: 0.3908\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3246\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3242 - val_loss: 0.0190 - val_accuracy: 0.2004\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3173\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3171 - val_loss: 0.0204 - val_accuracy: 0.4990\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.3188\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0180 - accuracy: 0.3186 - val_loss: 0.0216 - val_accuracy: 0.1984\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.3217\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0179 - accuracy: 0.3222 - val_loss: 0.0193 - val_accuracy: 0.4790\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3177\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0178 - accuracy: 0.3180 - val_loss: 0.0166 - val_accuracy: 0.4930\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3249\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3249 - val_loss: 0.0257 - val_accuracy: 0.2385\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3246\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0175 - accuracy: 0.3246 - val_loss: 0.0293 - val_accuracy: 0.3988\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3146\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.3149 - val_loss: 0.0207 - val_accuracy: 0.3407\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3159\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3160 - val_loss: 0.0193 - val_accuracy: 0.4870\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3146\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.3146 - val_loss: 0.0172 - val_accuracy: 0.3547\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.3195\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0174 - accuracy: 0.3200 - val_loss: 0.0302 - val_accuracy: 0.3968\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.3211\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0174 - accuracy: 0.3209 - val_loss: 0.0197 - val_accuracy: 0.2024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.3184\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 17s 11ms/step - loss: 0.0177 - accuracy: 0.3184 - val_loss: 0.0252 - val_accuracy: 0.4790\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3103\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.3102 - val_loss: 0.0235 - val_accuracy: 0.2064\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3251\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0177 - accuracy: 0.3249 - val_loss: 0.0211 - val_accuracy: 0.0782\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3164\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3162 - val_loss: 0.0210 - val_accuracy: 0.2004\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3258\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3255 - val_loss: 0.0183 - val_accuracy: 0.2425\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.3202\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0175 - accuracy: 0.3202 - val_loss: 0.0363 - val_accuracy: 0.4910\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.3122\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0178 - accuracy: 0.3122 - val_loss: 0.0310 - val_accuracy: 0.0782\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3280\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3278 - val_loss: 0.0302 - val_accuracy: 0.4128\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3217\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0178 - accuracy: 0.3215 - val_loss: 0.0160 - val_accuracy: 0.4649\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0179 - accuracy: 0.3189\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0179 - accuracy: 0.3189 - val_loss: 0.0189 - val_accuracy: 0.4930\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3191\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.3193 - val_loss: 0.0181 - val_accuracy: 0.3687\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3233\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3235 - val_loss: 0.0255 - val_accuracy: 0.3607\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3175\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3175 - val_loss: 0.0280 - val_accuracy: 0.2004\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.3162\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0174 - accuracy: 0.3164 - val_loss: 0.0176 - val_accuracy: 0.4790\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3103\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0175 - accuracy: 0.3106 - val_loss: 0.0250 - val_accuracy: 0.2004\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.3242\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3242 - val_loss: 0.0193 - val_accuracy: 0.4709\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3141\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3137 - val_loss: 0.0234 - val_accuracy: 0.2004\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3213\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3211 - val_loss: 0.0273 - val_accuracy: 0.2425\n",
      "1492/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3150\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3153 - val_loss: 0.0189 - val_accuracy: 0.2024\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.3220\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0174 - accuracy: 0.3218 - val_loss: 0.0229 - val_accuracy: 0.0782\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0173 - accuracy: 0.3213\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0173 - accuracy: 0.3213 - val_loss: 0.0348 - val_accuracy: 0.4449\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3233\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.3231 - val_loss: 0.0183 - val_accuracy: 0.4810\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.3198\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0178 - accuracy: 0.3198 - val_loss: 0.0231 - val_accuracy: 0.0782\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3094\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3093 - val_loss: 0.0192 - val_accuracy: 0.2425\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3298\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3298 - val_loss: 0.0186 - val_accuracy: 0.2244\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3195\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3200 - val_loss: 0.0320 - val_accuracy: 0.2004\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.3126\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3126 - val_loss: 0.0157 - val_accuracy: 0.4910\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3153\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.3153 - val_loss: 0.0258 - val_accuracy: 0.3848\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3215\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0177 - accuracy: 0.3220 - val_loss: 0.0183 - val_accuracy: 0.2224\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.3204\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3204 - val_loss: 0.0654 - val_accuracy: 0.2425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3151\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3146 - val_loss: 0.0206 - val_accuracy: 0.2485\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3264\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3269 - val_loss: 0.0211 - val_accuracy: 0.2786\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3162\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.3160 - val_loss: 0.0479 - val_accuracy: 0.4770\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3193\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3195 - val_loss: 0.0232 - val_accuracy: 0.4990\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.3164\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3164 - val_loss: 0.0172 - val_accuracy: 0.4850\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.3262\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.3262 - val_loss: 0.0264 - val_accuracy: 0.2224\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3289\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3282 - val_loss: 0.0186 - val_accuracy: 0.2285\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3226\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 18s 12ms/step - loss: 0.0178 - accuracy: 0.3229 - val_loss: 0.0268 - val_accuracy: 0.0782\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3160\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0178 - accuracy: 0.3160 - val_loss: 0.0199 - val_accuracy: 0.2405\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3101\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0178 - accuracy: 0.3102 - val_loss: 0.0179 - val_accuracy: 0.3868\n",
      "1492/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3204\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0178 - accuracy: 0.3206 - val_loss: 0.0197 - val_accuracy: 0.2425\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3104\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0175 - accuracy: 0.3106 - val_loss: 0.0160 - val_accuracy: 0.4749\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3170\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0175 - accuracy: 0.3173 - val_loss: 0.0180 - val_accuracy: 0.4429\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3119\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0178 - accuracy: 0.3120 - val_loss: 0.0196 - val_accuracy: 0.3507\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3211\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3211 - val_loss: 0.0167 - val_accuracy: 0.4930\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.3206\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0178 - accuracy: 0.3206 - val_loss: 0.0199 - val_accuracy: 0.2004\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3155\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.3160 - val_loss: 0.0178 - val_accuracy: 0.4830\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.3126\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0174 - accuracy: 0.3124 - val_loss: 0.0222 - val_accuracy: 0.2525\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3200\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 17s 11ms/step - loss: 0.0178 - accuracy: 0.3198 - val_loss: 0.0256 - val_accuracy: 0.2926\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3226\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0178 - accuracy: 0.3226 - val_loss: 0.0241 - val_accuracy: 0.2004\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.3300\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0173 - accuracy: 0.3300 - val_loss: 0.0252 - val_accuracy: 0.3948\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3213\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3213 - val_loss: 0.0286 - val_accuracy: 0.2465\n",
      "1492/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3219\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3220 - val_loss: 0.0192 - val_accuracy: 0.1924\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3184\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.3186 - val_loss: 0.0205 - val_accuracy: 0.2024\n",
      "1492/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3157\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0175 - accuracy: 0.3153 - val_loss: 0.0247 - val_accuracy: 0.4669\n",
      "1492/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3170\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3166 - val_loss: 0.0180 - val_accuracy: 0.4870\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3157\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0178 - accuracy: 0.3155 - val_loss: 0.0235 - val_accuracy: 0.4689\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3072\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.3075 - val_loss: 0.0401 - val_accuracy: 0.4810\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.3273\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0178 - accuracy: 0.3273 - val_loss: 0.0187 - val_accuracy: 0.4289\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3124\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 17s 11ms/step - loss: 0.0176 - accuracy: 0.3124 - val_loss: 0.0251 - val_accuracy: 0.2425\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1492/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3168\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3171 - val_loss: 0.0230 - val_accuracy: 0.2345\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3329\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.3331 - val_loss: 0.0184 - val_accuracy: 0.4790\n",
      "1492/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3132\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0178 - accuracy: 0.3126 - val_loss: 0.0204 - val_accuracy: 0.2004\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3251\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3255 - val_loss: 0.0257 - val_accuracy: 0.4269\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.3184\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0178 - accuracy: 0.3184 - val_loss: 0.0173 - val_accuracy: 0.4429\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3112\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 17s 12ms/step - loss: 0.0175 - accuracy: 0.3115 - val_loss: 0.0194 - val_accuracy: 0.1824\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3184\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3184 - val_loss: 0.0203 - val_accuracy: 0.2004\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0176 - accuracy: 0.3169\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3169 - val_loss: 0.0262 - val_accuracy: 0.3086\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3322\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.3322 - val_loss: 0.0429 - val_accuracy: 0.2064\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3202\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3198 - val_loss: 0.0258 - val_accuracy: 0.2064\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3213\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3215 - val_loss: 0.0219 - val_accuracy: 0.4449\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3191\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0177 - accuracy: 0.3191 - val_loss: 0.0191 - val_accuracy: 0.2305\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.3144\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0174 - accuracy: 0.3144 - val_loss: 0.0213 - val_accuracy: 0.2425\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.3206\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3206 - val_loss: 0.0227 - val_accuracy: 0.2004\n",
      "1492/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3097\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3097 - val_loss: 0.0210 - val_accuracy: 0.1784\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3197\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.3200 - val_loss: 0.0202 - val_accuracy: 0.4790\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3313\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0178 - accuracy: 0.3318 - val_loss: 0.0193 - val_accuracy: 0.4449\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3220\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3220 - val_loss: 0.0174 - val_accuracy: 0.2144\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3119\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3120 - val_loss: 0.0180 - val_accuracy: 0.4890\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.3140\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0175 - accuracy: 0.3140 - val_loss: 0.0640 - val_accuracy: 0.4509\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.3115\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0177 - accuracy: 0.3115 - val_loss: 0.0211 - val_accuracy: 0.2024\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3155\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3155 - val_loss: 0.0197 - val_accuracy: 0.4870\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3166\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0178 - accuracy: 0.3164 - val_loss: 0.0327 - val_accuracy: 0.2425\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3220\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 10ms/step - loss: 0.0176 - accuracy: 0.3218 - val_loss: 0.0171 - val_accuracy: 0.2405\n",
      "1493/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3251\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0177 - accuracy: 0.3255 - val_loss: 0.0215 - val_accuracy: 0.3888\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3150\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 16s 11ms/step - loss: 0.0176 - accuracy: 0.3153 - val_loss: 0.0268 - val_accuracy: 0.1142\n",
      "1492/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3161\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 17s 11ms/step - loss: 0.0177 - accuracy: 0.3155 - val_loss: 0.0328 - val_accuracy: 0.4128\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3191\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 19s 13ms/step - loss: 0.0175 - accuracy: 0.3195 - val_loss: 0.0219 - val_accuracy: 0.2425\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3318\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 21s 14ms/step - loss: 0.0176 - accuracy: 0.3318 - val_loss: 0.0320 - val_accuracy: 0.2004\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0177 - accuracy: 0.3169\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 25s 17ms/step - loss: 0.0177 - accuracy: 0.3169 - val_loss: 0.0455 - val_accuracy: 0.0962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3264\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 22s 15ms/step - loss: 0.0176 - accuracy: 0.3271 - val_loss: 0.0374 - val_accuracy: 0.2004\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0178 - accuracy: 0.3111\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 24s 16ms/step - loss: 0.0178 - accuracy: 0.3111 - val_loss: 0.0323 - val_accuracy: 0.4669\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3168\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 21s 14ms/step - loss: 0.0175 - accuracy: 0.3169 - val_loss: 0.0280 - val_accuracy: 0.1864\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0174 - accuracy: 0.3162\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 26s 17ms/step - loss: 0.0174 - accuracy: 0.3162 - val_loss: 0.0247 - val_accuracy: 0.4790\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3115\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 27s 18ms/step - loss: 0.0176 - accuracy: 0.3113 - val_loss: 0.0186 - val_accuracy: 0.1723\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0178 - accuracy: 0.3229\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 22s 15ms/step - loss: 0.0178 - accuracy: 0.3229 - val_loss: 0.0202 - val_accuracy: 0.4890\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0177 - accuracy: 0.3059\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 27s 18ms/step - loss: 0.0177 - accuracy: 0.3059 - val_loss: 0.0249 - val_accuracy: 0.4749\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3393\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 26s 17ms/step - loss: 0.0175 - accuracy: 0.3393 - val_loss: 0.0178 - val_accuracy: 0.2004\n",
      "1496/1497 [============================>.] - ETA: 0s - loss: 0.0175 - accuracy: 0.3249\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 27s 18ms/step - loss: 0.0175 - accuracy: 0.3249 - val_loss: 0.0216 - val_accuracy: 0.3066\n",
      "1495/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3097\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 30s 20ms/step - loss: 0.0176 - accuracy: 0.3093 - val_loss: 0.0195 - val_accuracy: 0.2265\n",
      "1497/1497 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.3142\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 23s 16ms/step - loss: 0.0175 - accuracy: 0.3142 - val_loss: 0.0249 - val_accuracy: 0.2425\n",
      "1494/1497 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.3264\n",
      "Epoch 1: val_accuracy did not improve from 0.49900\n",
      "1497/1497 [==============================] - 21s 14ms/step - loss: 0.0177 - accuracy: 0.3262 - val_loss: 0.0200 - val_accuracy: 0.2044\n",
      "1262/1497 [========================>.....] - ETA: 3s - loss: 0.0179 - accuracy: 0.3030"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-166-37795eadb099>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m             \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             callbacks=[checkpoint])\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;31m#model.save_weights('my_model_weights2.h5')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'my_model_weights2.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensorflow\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1407\u001b[0m                 _r=1):\n\u001b[0;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1410\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    916\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    945\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    946\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 947\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    948\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    949\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m   2453\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m-> 2454\u001b[1;33m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[0;32m   2455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2456\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1859\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1860\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1861\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    500\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    503\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    504\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\.conda\\envs\\Tensorflow\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 55\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     56\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"my_model_weights2.h5\", monitor='val_accuracy', verbose=1,\n",
    "    save_best_only=True, mode='auto', period=1)\n",
    "early_stopping_monitor = EarlyStopping(patience=2)\n",
    "\n",
    "i = 0\n",
    "while i < 200:\n",
    "    model.fit(train, \n",
    "            label,\n",
    "          batch_size = 3, \n",
    "            epochs = 1,\n",
    "            validation_split=0.1,\n",
    "            callbacks=[checkpoint])\n",
    "    #model.save_weights('my_model_weights2.h5')\n",
    "    model.load_weights('my_model_weights2.h5')\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8BMU8Gb4TiZF",
    "outputId": "4ed4f90f-b8d1-4aa0-b2f4-59b1ad7f0359"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2495/2495 [==============================] - 21s 8ms/step - loss: 0.0187 - accuracy: 0.3437\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.018728548660874367, 0.34368738532066345]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(train, label, batch_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled8.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
